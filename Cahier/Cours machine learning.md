---
Created: 2023-04-03T14:58
---
# Hugging Face ğŸ¤— Course
## Transformer models
### Using Transformers
- On peut importer un modÃ¨le sans forcÃ©ment importer ses weights (Ã  partir du config file, qui indique lâ€™architecture du modÃ¨le, le nombre de couches etcâ€¦)
### Tokenizers
- 3 diffÃ©rents algorithmes de tokenization
    - **Word based** (1 mot = 1 token)
        - ProblÃ¨mes : les mots proches sont Ã©loignÃ©s, aussi grand que le vocabulaire de la langue (peut Ãªtre Ã©norme)
    - **Character based** **(1 caractÃ¨re = 1 token)**
        - Permet un dictionnaire beaucoup plus petit
        - ProblÃ¨mes : les caractÃ¨res retiennent peu dâ€™information (dans des langues romanes notamment) **&** rÃ©duit le nombre de caractÃ¨res possibles en input
    - **Sub word based** **(1 mot = plusieurs token, ex : dogs -> dog + s)**
        - permet de regrouper les sous-mots communes dâ€™une langue (comme Â«Â izationÂ Â» ou Â«Â isteÂ Â»)
        - Les mots communs ne sont pas sÃ©parÃ©s en sous-mots
        - Exemples de models : WordPiece (BERT), Unigram (ALBERT), Byte-Pair Encoding (GPT-2)
### Handling multiple sequences
- Les input doivent toutes avoir la mÃªme longueur pour Ãªtre comparables dans le modÃ¨le, il faut donc :
    - Ã‰courter les inputs trop longs (rare, on fixe le maximum comme Ã©tant le maximum du modÃ¨le)
    - Ajouter des caractÃ¨res, du Â«Â paddingÂ Â» Ã  la fin des petits inputs pour quâ€™ils arrivent Ã  la taille des grandes.
        - On voit le caractÃ¨re de padding avec
            
            `tokenizer.pad_token_id`
            
- Les modÃ¨les sont souvent limitÃ©s Ã  512 ou 1024 tokens et crashent aprÃ¨s.
  
### Autres infos de fin
- Le Â«Â model headÂ Â» est le composant qui transforme la prÃ©diction en un output spÃ©cifiÃ© sur une tÃ¢che (traduction, q&a, classificationâ€¦)
- Le `auto_model` permet de charger la bonne architecture de modÃ¨le Ã  partir du checkpoint (weights) uniquement
- On applique le `softmax` Ã  lâ€™output dâ€™un modÃ¨le de sequence classification pour
  
  
# Fine-Tuning